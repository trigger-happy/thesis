\subsubsection*{Context of the Study}
Genetic algorithms are one of the many types of artificial intelligence
techniques that exist today. If implemented well, genetic algorithms can
evolve a computer controlled agent to perform adequately according to some
set criteria defined in a fitness function. However, a significant amount of 
time is required for the algorithm to evolve a population of individual solutions 
into an acceptable solution. The time it takes can range from a few hours to a number
of weeks, depending on the complexity of the game where the agent must perform.
This limitation makes them difficult or impractical to use in the process of
game development.


The primary reasons genetic algorithms take up a lot of time are the number of 
possible solutions that must be tested given a specific generation, the time it 
takes to evaluate each of these possible solutions, and the number of generations 
that may be needed before arriving at a single or a number of acceptable solutions. 
Modern day CPUs may be fast, but they can only reduce
the running time of a genetic algorithm by so much. A common solution to the
problem is through parallelization across multiple CPUs either in a computing
cluster or through multiple processors. These solutions however are either
too expensive or still insufficient.


A single computer processor is capable of a variety of things, but it can only process
one thing at a time. This is where Graphics Processing Units, or GPUs, come in.
GPUs have been designed to execute a single set of instructions over numerous elements
of data. Not only do they have multiple processing units, each processing unit is also
capable of running several identical instructions simultaneously, making GPUs ideal
for highly parallel algorithms. It is our goal therefore to show that GPUs can be used
for evolving computer controlled agents for use in computer games at a rate that is much
faster than those that are evolved through the use of a CPU.